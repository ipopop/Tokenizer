class Tokenizer:
    def __init__(self):
        pass

    def tokenize(self, text):
        return []

    def token_frequency(self, text):
        return {}

    def generate_word_cloud(self, text):
        return None

    def remove_stopwords(self, text):
        return text

    def remove_punctuation_and_numbers(self, text):
        return text